---
title: "Introduction to `{gardenr}`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to `{gardenr}`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Example

Here is an example of using `cross_validate_it()` to help with hyperparameter tuning. 

```{r setup, message=FALSE, warning=FALSE}
library(gardenr)
library(glmertree)
library(dplyr)
```

## Simulate some data

We can start by simulating some multilevel data using the `sim_multilevel()` function. See `?sim_multilevel()` for defaults and other details. In this example, I have made the standard deviation of the residual variance large at both level 1 and level 2 to make the difference between default hyperparameters and tuned models more dramatic (to help illustrate the problems the package helps solve).

```{r}
dat <- sim_multilevel(residual_var_sd_1 = 2, residual_var_sd_2 = 6)
```

## Split Data & Make CV Object

The package is built off the `{tidymodels}` framework, so we can use `{rsample}` to split the data and make a cross-validation object. 

```{r}
example_split <- rsample::initial_split(dat)
example_train <- rsample::training(example_split)
example_test  <-  rsample::testing(example_split)
cv <- rsample::vfold_cv(data = example_train, v = 10)
```

## Make a `Formula` object

This is the proposed GLMM tree formula. This is *not* a normal `formula` object, but a `Formula` object instead. See `?Formula::as.Formula` for an explanation of the differences.

```{r}
ex_formula <-
   Formula::as.Formula(
      'outcome ~ small_1 |
      (1 | id_vector) |
      small_2 + small_c_1 + small_c_2 + nuisance_1a + nuisance_c_1a'
      )
```

## Make a Tuning Grid

We can then use dials to make a tuning grid. Notice that the parameter objects for GLMM trees have already been made and are in `{gardenr}` (e.g., `alpha_par()`)

```{r}
tuning_grid <-
  dials::grid_max_entropy(
    maxdepth_par(maxdepth_min = 2L, maxdepth_max = 20L),
    alpha_par(alpha_min = 0.10, alpha_max = 0.001),
    trim_par(trim_min = 0.01, trim_max = 0.5),
    size = 10
  )
tuning_grid
```

## Fit the Model to the Cross-Validated Data

Here we fit the model to the cross-validated object.

```{r message=FALSE}
fitted <-
   cross_validate_it(
      cv_obj = cv,
      seed = 713,
      tuning_grid = tuning_grid,
      mod_formula = ex_formula, 
      cluster = id_vector
      )
```

## See Best Fitting Hyperparameters

```{r}
best_fit <- 
  fitted %>% 
  arrange(mean_rmse) 
best_fit
```

```{r}
best_fit_trained <- 
  lmertree(
    data = example_train, 
    formula = 
      ex_formula, 
    maxdepth = best_fit$maxdepth_par[1], 
    alpha = best_fit$alpha_par[1],
    trim = best_fit$trim_par[1], 
    cluster = id_vector,
    verbose = TRUE
  )
```

## See Splits as Plot

```{r fig.width = 8, fig.height = 8}
plot(
  best_fit_trained, 
  which = 'tree',
  )
```

```{r fig.width = 8, fig.height = 8}
plot(
  best_fit_trained, 
  which = 'tree.coef',
  )
```

## Compare this to a tree with default hyperparameters

It's clear that this tree has made many more splits than the trained model. 

```{r}
untrained <- 
  lmertree(
    data = example_train, 
    formula = 
      ex_formula, 
    cluster = id_vector,
    verbose = TRUE
  )
```

```{r fig.width = 12, fig.height = 12}
plot(
  untrained,  
  which = 'tree'
  )
```

```{r fig.width = 8, fig.height = 8}
plot(
  untrained, 
  which = 'tree.coef',
  )
```

## Get RMSE for unseen data

We see here that the model fits unseen data slightly better than the model with default hyperparameters.

```{r}
example_test %>% 
  mutate(
    predictions_tuned =
      predict(
        best_fit_trained, 
        newdata = ., 
        allow.new.levels = TRUE
        ),
    predictions_default_hyperparams =
      predict(
        untrained, 
        newdata = ., 
        allow.new.levels = TRUE
        ),
    ) %>% 
  summarize(
    tuned_RMSE = 
      rmse(observed_y = outcome, predicted_y = predictions_tuned),
    default_hyperparams_RMSE = 
      rmse(observed_y = outcome, predicted_y = predictions_default_hyperparams)
    )

```

