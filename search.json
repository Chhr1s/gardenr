[{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Introduction to `{gardenr}`","text":"example using cross_validate_it() help hyperparameter tuning.","code":"#devtools::install_github(\"Chhr1s/gardenr\") library(gardenr) library(glmertree) library(dplyr)"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"simulate-some-data","dir":"Articles","previous_headings":"","what":"Simulate some data","title":"Introduction to `{gardenr}`","text":"’s function within package simulate multilevel data. defaults, can changed. use ?sim_multilevel() details. made standard deviation residual variance large example level 1 level 2 make difference default hyperparameters tuned models dramatic.","code":"dat <- sim_multilevel(residual_var_sd_1 = 2, residual_var_sd_2 = 6)"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"split-data-make-cv-object","dir":"Articles","previous_headings":"","what":"Split Data & Make CV Object","title":"Introduction to `{gardenr}`","text":"Wherever possible, wanted rely good functions tidymodels framework. can use rsample spit data make cross-validation object.","code":"example_split <- rsample::initial_split(dat) example_train <- rsample::training(example_split) example_test  <-  rsample::testing(example_split) cv <- rsample::vfold_cv(data = example_train, v = 10)"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"make-a-formula-object","dir":"Articles","previous_headings":"","what":"Make a Formula object","title":"Introduction to `{gardenr}`","text":"proposed GLMM tree formula. normal formula object, Formula object instead. See ?Formula::.Formula explanation differences.","code":"ex_formula <-    Formula::as.Formula(       'outcome ~ small_1 |       (1 | id_vector) |       small_2 + small_c_1 + small_c_2 + nuisance_1a + nuisance_c_1a'       )"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"make-a-tuning-grid","dir":"Articles","previous_headings":"","what":"Make a Tuning Grid","title":"Introduction to `{gardenr}`","text":"can use dials make tuning grid. Notice parameter objects GLMM trees already made gardenr (e.g., alpha_par())","code":"tuning_grid <-   dials::grid_max_entropy(     maxdepth_par(maxdepth_min = 2L, maxdepth_max = 20L),     alpha_par(alpha_min = 0.10, alpha_max = 0.001),     trim_par(trim_min = 0.01, trim_max = 0.5),     size = 10   ) tuning_grid #> # A tibble: 10 × 3 #>    maxdepth_par alpha_par trim_par #>           <int>     <dbl>    <dbl> #>  1           13   0.0996    0.402  #>  2           19   0.0548    0.0993 #>  3           14   0.00564   0.0229 #>  4           10   0.0447    0.158  #>  5           19   0.00537   0.273  #>  6           11   0.0116    0.453  #>  7           15   0.0476    0.334  #>  8            2   0.0664    0.471  #>  9           12   0.0811    0.0343 #> 10            3   0.0837    0.0433"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"fit-the-model-to-the-cross-validated-data","dir":"Articles","previous_headings":"","what":"Fit the Model to the Cross-Validated Data","title":"Introduction to `{gardenr}`","text":"fit model cross-validated object.","code":"fitted <-    cross_validate_it(       cv_obj = cv,       seed = 713,       tuning_grid = tuning_grid,       mod_formula = ex_formula,        cluster = id_vector       )"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"see-best-fitting-hyperparameters","dir":"Articles","previous_headings":"","what":"See Best Fitting Hyperparameters","title":"Introduction to `{gardenr}`","text":"","code":"best_fit <-    fitted %>%    arrange(mean_rmse)  best_fit #> # A tibble: 10 × 8 #>    grid_index maxdepth_par alpha_par trim_par mean_rmse se_rmse mean_mae  se_mae #>         <int>        <int>     <dbl>    <dbl>     <dbl>   <dbl>    <dbl>   <dbl> #>  1         10            3   0.0837    0.0433      2.05  0.0352   0.0125 1.80e-4 #>  2          6           11   0.0116    0.453       2.05  0.0350   0.0124 1.90e-4 #>  3          8            2   0.0664    0.471       2.05  0.0365   0.0125 1.97e-4 #>  4          5           19   0.00537   0.273       2.06  0.0366   0.0125 2.03e-4 #>  5          3           14   0.00564   0.0229      2.07  0.0358   0.0125 1.96e-4 #>  6          4           10   0.0447    0.158       2.07  0.0344   0.0125 1.85e-4 #>  7          2           19   0.0548    0.0993      2.07  0.0328   0.0126 1.76e-4 #>  8          7           15   0.0476    0.334       2.07  0.0367   0.0125 1.99e-4 #>  9          1           13   0.0996    0.402       2.08  0.0356   0.0126 1.93e-4 #> 10          9           12   0.0811    0.0343      2.08  0.0336   0.0126 1.86e-4 best_fit_trained <-    lmertree(     data = example_train,      formula =        ex_formula,      maxdepth = best_fit$maxdepth_par[1],      alpha = best_fit$alpha_par[1],     trim = best_fit$trim_par[1],      cluster = id_vector,     verbose = TRUE   ) #> 'log Lik.' -3015.466 (df=4) #> 'log Lik.' -3011.777 (df=10) #> 'log Lik.' -3011.777 (df=10)"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"see-splits-as-plot","dir":"Articles","previous_headings":"","what":"See Splits as Plot","title":"Introduction to `{gardenr}`","text":"","code":"plot(   best_fit_trained,    which = 'tree',   ) plot(   best_fit_trained,    which = 'tree.coef',   )"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"compare-this-to-a-tree-with-default-hyperparameters","dir":"Articles","previous_headings":"","what":"Compare this to a tree with default hyperparameters","title":"Introduction to `{gardenr}`","text":"’s clear tree made many splits trained model.","code":"untrained <-    lmertree(     data = example_train,      formula =        ex_formula,      cluster = id_vector,     verbose = TRUE   ) #> 'log Lik.' -3015.466 (df=4) #> 'log Lik.' -3009.867 (df=16) #> 'log Lik.' -3004.441 (df=18) #> 'log Lik.' -3003.055 (df=18) #> 'log Lik.' -3004.441 (df=18) #> 'log Lik.' -3003.055 (df=18) plot(   untrained,     which = 'tree'   ) plot(   untrained,    which = 'tree.coef',   )"},{"path":"https://chhr1s.github.io/gardenr/articles/intro-gardenr.html","id":"get-rmse-for-unseen-data","dir":"Articles","previous_headings":"","what":"Get RMSE for unseen data","title":"Introduction to `{gardenr}`","text":"see model fits unseen data slightly better model default hyperparameters.","code":"example_test %>%    mutate(     predictions_tuned =       predict(         best_fit_trained,          newdata = .,          allow.new.levels = TRUE         ),     predictions_default_hyperparams =       predict(         untrained,          newdata = .,          allow.new.levels = TRUE         ),     ) %>%    summarize(     tuned_RMSE =        rmse(observed_y = outcome, predicted_y = predictions_tuned),     default_hyperparams_RMSE =        rmse(observed_y = outcome, predicted_y = predictions_default_hyperparams)     ) #>   tuned_RMSE default_hyperparams_RMSE #> 1   2.020963                 2.044691"},{"path":"https://chhr1s.github.io/gardenr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Christopher M. Loan. Author, maintainer.","code":""},{"path":"https://chhr1s.github.io/gardenr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Loan C (2022). gardenr: Package (One Line, Title Case). R package version 0.0.0.9000, https://chhr1s.github.io/gardenr/.","code":"@Manual{,   title = {gardenr: What the Package Does (One Line, Title Case)},   author = {Christopher M. Loan},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://chhr1s.github.io/gardenr/}, }"},{"path":"https://chhr1s.github.io/gardenr/index.html","id":"gardenr","dir":"","previous_headings":"","what":"What the Package Does (One Line, Title Case)","title":"What the Package Does (One Line, Title Case)","text":"goal gardenr provide tools general linear mixed effects model regression (GLMM) trees implemented {glmertree} package.","code":""},{"path":"https://chhr1s.github.io/gardenr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"What the Package Does (One Line, Title Case)","text":"can install development version gardenr GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"Chhr1s/gardenr\")"},{"path":"https://chhr1s.github.io/gardenr/index.html","id":"purpose","dir":"","previous_headings":"","what":"purpose","title":"What the Package Does (One Line, Title Case)","text":"purpose gardenr package improve workflows model-based recursive partitioning. includes GLM trees, GLMM trees, soon incorporate variants. present, mostly cross-validation improvements tune hyperparameters, extend novel pruning mechanisms. Please see vignette examples.","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/alpha_par.html","id":null,"dir":"Reference","previous_headings":"","what":"make parameter for tuning level of significance in instability tests — alpha_par","title":"make parameter for tuning level of significance in instability tests — alpha_par","text":"make parameter tuning level significance instability tests","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/alpha_par.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make parameter for tuning level of significance in instability tests — alpha_par","text":"","code":"alpha_par(alpha_min = 0.001, alpha_max = 0.05)"},{"path":"https://chhr1s.github.io/gardenr/reference/alpha_par.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make parameter for tuning level of significance in instability tests — alpha_par","text":"alpha_min integer specifying minimum value parameter grid alpha_max integer specifying maximum value parameter grid","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/alpha_par.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make parameter for tuning level of significance in instability tests — alpha_par","text":"quantitative parameter, {dials} maxdepth","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/alpha_par.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make parameter for tuning level of significance in instability tests — alpha_par","text":"","code":"dials::grid_max_entropy(    maxdepth_par(maxdepth_min = 2, maxdepth_max = 5),    alpha_par(alpha_min = 0.10, alpha_max = 0.001),    trim_par(trim_min = 0.1, trim_max = 0.3),    size = 10    ) #> # A tibble: 10 × 3 #>    maxdepth_par alpha_par trim_par #>           <int>     <dbl>    <dbl> #>  1            5   0.00955    0.128 #>  2            3   0.0414     0.140 #>  3            5   0.0563     0.176 #>  4            2   0.0981     0.114 #>  5            4   0.00474    0.243 #>  6            3   0.00160    0.116 #>  7            4   0.0797     0.259 #>  8            2   0.0186     0.271 #>  9            2   0.0758     0.245 #> 10            4   0.0961     0.142"},{"path":"https://chhr1s.github.io/gardenr/reference/cross_validate_it.html","id":null,"dir":"Reference","previous_headings":"","what":"fit glmertree() to a cross-validated data set — cross_validate_it","title":"fit glmertree() to a cross-validated data set — cross_validate_it","text":"fit glmertree() cross-validated data set","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/cross_validate_it.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fit glmertree() to a cross-validated data set — cross_validate_it","text":"","code":"cross_validate_it(cv_obj, seed = 713, mod_formula, tuning_grid = NULL, ...)"},{"path":"https://chhr1s.github.io/gardenr/reference/cross_validate_it.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fit glmertree() to a cross-validated data set — cross_validate_it","text":"cv_obj vfold_cv—v-fold cross-validated dataset rsample::vfold_cv() seed integer—starting seed mod_formula Formula—made .Formula(). uppercase required :) tuning_grid — either tuning grid e.g., dials::grid_max_entropy() default grid (tuning_grid = NULL). ... additional arguments passed glmertree()","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/cross_validate_it.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fit glmertree() to a cross-validated data set — cross_validate_it","text":"tibble—fit statistics (rmse, mae) object","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/cross_validate_it.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"fit glmertree() to a cross-validated data set — cross_validate_it","text":"","code":"dat <- sim_multilevel() example_split <- rsample::initial_split(dat) example_train <- rsample::training(example_split) example_test  <-  rsample::testing(example_split) cv <- rsample::vfold_cv(data = example_train, v = 10)  ex_formula <-    Formula::as.Formula(       'outcome ~ small_1 |       (1 | id_vector) |       small_c_1 + small_c_2 + nuisance_1a + nuisance_c_1a'       )  tuning_grid <-   dials::grid_max_entropy(     maxdepth_par(maxdepth_min = 0L, maxdepth_max = 20L),     alpha_par(alpha_min = 0.10, alpha_max = 0.001),     trim_par(trim_min = 0.01, trim_max = 0.5),     size = 10   )  fitted <-    cross_validate_it(       cv_obj = cv,       seed = 713,       tuning_grid = tuning_grid,       mod_formula = ex_formula       ) #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 1 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 2 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 3 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 4 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 5 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 6 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 7 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 8 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 9 complete #> cv index 1 complete #> cv index 2 complete #> cv index 3 complete #> cv index 4 complete #> cv index 5 complete #> cv index 6 complete #> cv index 7 complete #> cv index 8 complete #> cv index 9 complete #> cv index 10 complete #> hyperparameter index 10 complete"},{"path":"https://chhr1s.github.io/gardenr/reference/mae.html","id":null,"dir":"Reference","previous_headings":"","what":"mean absolute error — mae","title":"mean absolute error — mae","text":"mean absolute error","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mean absolute error — mae","text":"","code":"mae(observed_y, predicted_y)"},{"path":"https://chhr1s.github.io/gardenr/reference/mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mean absolute error — mae","text":"observed_y numeric vector observed ys. predicted_y numeric vector predictions y.","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mean absolute error — mae","text":"double vector length 1","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/mae.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mean absolute error — mae","text":"","code":"set.seed(1) obs_y <- rnorm(4) pred_y <- rnorm(4) mae(observed_y = obs_y, predicted_y = pred_y) #> [1] 0.2587554"},{"path":"https://chhr1s.github.io/gardenr/reference/maxdepth_par.html","id":null,"dir":"Reference","previous_headings":"","what":"make parameter for tuning maximum depth of tree — maxdepth_par","title":"make parameter for tuning maximum depth of tree — maxdepth_par","text":"make parameter tuning maximum depth tree","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/maxdepth_par.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make parameter for tuning maximum depth of tree — maxdepth_par","text":"","code":"maxdepth_par(maxdepth_min = 2, maxdepth_max = 12)"},{"path":"https://chhr1s.github.io/gardenr/reference/maxdepth_par.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make parameter for tuning maximum depth of tree — maxdepth_par","text":"maxdepth_min integer specifying minimum value parameter grid maxdepth_max integer specifying maximum value parameter grid","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/maxdepth_par.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make parameter for tuning maximum depth of tree — maxdepth_par","text":"quantitative parameter, {dials} maxdepth","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/maxdepth_par.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make parameter for tuning maximum depth of tree — maxdepth_par","text":"","code":"dials::grid_max_entropy(    maxdepth_par(maxdepth_min = 2, maxdepth_max = 5),    alpha_par(alpha_min = 0.10, alpha_max = 0.001),    trim_par(trim_min = 0.1, trim_max = 0.3),    size = 10    ) #> # A tibble: 10 × 3 #>    maxdepth_par alpha_par trim_par #>           <int>     <dbl>    <dbl> #>  1            5    0.0842    0.122 #>  2            5    0.0456    0.289 #>  3            3    0.0185    0.281 #>  4            2    0.0369    0.230 #>  5            5    0.0796    0.213 #>  6            3    0.0637    0.102 #>  7            3    0.0757    0.260 #>  8            5    0.0181    0.215 #>  9            2    0.0133    0.114 #> 10            4    0.0992    0.182"},{"path":"https://chhr1s.github.io/gardenr/reference/rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"root mean square error of approximation — rmse","title":"root mean square error of approximation — rmse","text":"root mean square error approximation","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"root mean square error of approximation — rmse","text":"","code":"rmse(observed_y, predicted_y)"},{"path":"https://chhr1s.github.io/gardenr/reference/rmse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"root mean square error of approximation — rmse","text":"observed_y numeric vector observed ys. predicted_y numeric vector predictions y.","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/rmse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"root mean square error of approximation — rmse","text":"double vector length 1","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/rmse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"root mean square error of approximation — rmse","text":"","code":"set.seed(1) obs_y <- rnorm(4) pred_y <- rnorm(4) rmse(observed_y = obs_y, predicted_y = pred_y) #> [1] 1.049638"},{"path":"https://chhr1s.github.io/gardenr/reference/sim_multilevel.html","id":null,"dir":"Reference","previous_headings":"","what":"simulate tibble of two-level data with outcome,\nid_vector, and categorical/continuous covariates with varied magnitudes of effect.\nNuisance predictors (orthogonal to outcome) also included. — sim_multilevel","title":"simulate tibble of two-level data with outcome,\nid_vector, and categorical/continuous covariates with varied magnitudes of effect.\nNuisance predictors (orthogonal to outcome) also included. — sim_multilevel","text":"simulate tibble two-level data outcome, id_vector, categorical/continuous covariates varied magnitudes effect. Nuisance predictors (orthogonal outcome) also included.","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/sim_multilevel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulate tibble of two-level data with outcome,\nid_vector, and categorical/continuous covariates with varied magnitudes of effect.\nNuisance predictors (orthogonal to outcome) also included. — sim_multilevel","text":"","code":"sim_multilevel(   j = 116,   intercept_1 = 0,   residual_var_sd_1 = 0.4,   random_int_mean_2 = 0,   residual_var_sd_2 = 0.1,   start_seed = 713,   num_in_groups = rpois(n = j, lambda = 15) )"},{"path":"https://chhr1s.github.io/gardenr/reference/sim_multilevel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"simulate tibble of two-level data with outcome,\nid_vector, and categorical/continuous covariates with varied magnitudes of effect.\nNuisance predictors (orthogonal to outcome) also included. — sim_multilevel","text":"j integer—number level 2 units intercept_1 double—intercept level 1 residual_var_sd_1 double—standard deviation residuals level 1 random_int_mean_2 double—mean random intercept level 2 residual_var_sd_2 double—standard deviation random intercept level 2, start_seed integer—starting seed, num_in_groups numeric vector—number observations per group length argument j","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/sim_multilevel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"simulate tibble of two-level data with outcome,\nid_vector, and categorical/continuous covariates with varied magnitudes of effect.\nNuisance predictors (orthogonal to outcome) also included. — sim_multilevel","text":"tibble","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/sim_multilevel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"simulate tibble of two-level data with outcome,\nid_vector, and categorical/continuous covariates with varied magnitudes of effect.\nNuisance predictors (orthogonal to outcome) also included. — sim_multilevel","text":"","code":"J <- 116    dat <-       sim_multilevel(          j = J,          intercept_1 = 0,          residual_var_sd_1 = 0.7,          random_int_mean_2 = 0,          residual_var_sd_2 = 0.3,          start_seed = 713,          num_in_groups = rpois(n = J, lambda = 15)         )"},{"path":"https://chhr1s.github.io/gardenr/reference/trim_par.html","id":null,"dir":"Reference","previous_headings":"","what":"make parameter for tuning level of amount of outlier trimmed in instability tests — trim_par","title":"make parameter for tuning level of amount of outlier trimmed in instability tests — trim_par","text":"make parameter tuning level amount outlier trimmed instability tests","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/trim_par.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make parameter for tuning level of amount of outlier trimmed in instability tests — trim_par","text":"","code":"trim_par(trim_min = 0.1, trim_max = 0.5)"},{"path":"https://chhr1s.github.io/gardenr/reference/trim_par.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make parameter for tuning level of amount of outlier trimmed in instability tests — trim_par","text":"trim_min integer specifying minimum value parameter grid trim_max integer specifying maximum value parameter grid","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/trim_par.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make parameter for tuning level of amount of outlier trimmed in instability tests — trim_par","text":"quantitative parameter, {dials} maxdepth","code":""},{"path":"https://chhr1s.github.io/gardenr/reference/trim_par.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make parameter for tuning level of amount of outlier trimmed in instability tests — trim_par","text":"","code":"dials::grid_max_entropy(    maxdepth_par(maxdepth_min = 2, maxdepth_max = 5),    alpha_par(alpha_min = 0.10, alpha_max = 0.001),    trim_par(trim_min = 0.1, trim_max = 0.3),    size = 10    ) #> # A tibble: 10 × 3 #>    maxdepth_par alpha_par trim_par #>           <int>     <dbl>    <dbl> #>  1            5   0.0118     0.165 #>  2            5   0.0856     0.279 #>  3            5   0.0574     0.120 #>  4            3   0.00844    0.210 #>  5            2   0.0992     0.172 #>  6            3   0.0530     0.145 #>  7            2   0.0480     0.255 #>  8            4   0.0981     0.273 #>  9            5   0.0192     0.269 #> 10            5   0.0978     0.187"}]
